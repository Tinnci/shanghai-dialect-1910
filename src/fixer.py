"""
Ruby å¯¹è‡ªåŠ¨ä¿®å¤æ¨¡å—
æ”¯æŒäº¤äº’å¼ä¿®å¤ã€å¹²è¿è¡Œå’Œè‡ªåŠ¨æ¨¡å¼
"""
import re
import shutil
from pathlib import Path
from dataclasses import dataclass
from enum import Enum, auto
from typing import List, Optional, Dict
from collections import defaultdict

from .loader import LessonFile, load_lessons
from .utils import split_characters, get_similarity, normalize_pinyin
from .rime_dict import is_valid_pronunciation

class FixStrategy(Enum):
    SPLIT_RUBY = auto()      # æ‹†åˆ†ï¼šæ±‰å­—å¤šäºæ‹¼éŸ³
    MERGE_RUBY = auto()      # åˆå¹¶ï¼šæ‹¼éŸ³å¤šäºæ±‰å­—
    REPLACE_PINYIN = auto()  # æ›¿æ¢ï¼šæ‹¼å†™é”™è¯¯
    MANUAL = auto()          # æ— æ³•è‡ªåŠ¨å¤„ç†

class SafetyLevel(Enum):
    """è‡ªåŠ¨ä¿®å¤å®‰å…¨ç­‰çº§"""
    SAFE = auto()        # å¯å®‰å…¨è‡ªåŠ¨ä¿®å¤ (ç½®ä¿¡åº¦ > 95%)
    REVIEW = auto()      # å»ºè®®äººå·¥å®¡æ ¸ (ç½®ä¿¡åº¦ 70-95%)
    MANUAL = auto()      # å¿…é¡»äººå·¥å¤„ç† (ç½®ä¿¡åº¦ < 70%)

@dataclass
class FixSuggestion:
    """å•æ¡ä¿®å¤å»ºè®®"""
    file: str
    line_num: int
    strategy: FixStrategy
    original: str           # åŸå§‹ #r(...) æ–‡æœ¬
    problem: str            # é—®é¢˜æè¿°
    suggestion: str         # å»ºè®®çš„ä¿®å¤åæ–‡æœ¬
    confidence: float       # ç½®ä¿¡åº¦ (0-1)
    safety: SafetyLevel = SafetyLevel.MANUAL
    needs_input: bool = False  # æ˜¯å¦éœ€è¦ç”¨æˆ·è¾“å…¥
    missing_char: str = ""     # éœ€è¦ç”¨æˆ·æä¾›æ‹¼éŸ³çš„æ±‰å­—
    context_before: str = ""   # å‰æ–‡ä¸Šä¸‹æ–‡
    context_after: str = ""    # åæ–‡ä¸Šä¸‹æ–‡
    corpus_examples: List[str] = None  # å…¨ä¹¦ä¸­è¯¥å­—çš„å…¶ä»–ç”¨ä¾‹
    
    def __post_init__(self):
        if self.corpus_examples is None:
            self.corpus_examples = []

@dataclass
class CharPronInfo:
    """æ±‰å­—å‘éŸ³ä¿¡æ¯"""
    main_pinyin: str
    main_count: int
    total_count: int
    all_pinyins: Dict[str, int]
    examples: List[str]  # ç¤ºä¾‹: ["lesson-1.typ: #r('kuh', 'ä¸ª')"]
    
    @property
    def confidence(self) -> float:
        return self.main_count / self.total_count if self.total_count > 0 else 0
    
    @property
    def is_polyphonic(self) -> bool:
        """æ˜¯å¦å¯èƒ½æ˜¯å¤šéŸ³å­— (ç¬¬äºŒå¸¸è§è¯»éŸ³å æ¯” > 15%)"""
        if len(self.all_pinyins) < 2:
            return False
        sorted_counts = sorted(self.all_pinyins.values(), reverse=True)
        second_ratio = sorted_counts[1] / self.total_count
        return second_ratio > 0.15

def build_pronunciation_db(lessons: List[LessonFile]) -> Dict[str, CharPronInfo]:
    """ä»å…¨ä¹¦æ„å»ºæ±‰å­—-å‘éŸ³ä¿¡æ¯æ•°æ®åº“ (å¸¦ç»Ÿè®¡å’Œç¤ºä¾‹)"""
    char_data = defaultdict(lambda: {"counts": defaultdict(int), "examples": defaultdict(list)})
    
    for lesson in lessons:
        for pair in lesson.pairs:
            p_parts = re.split(r'[-\s]', pair.normalized_pinyin)
            h_chars = split_characters(pair.hanzi)
            
            if len(p_parts) == len(h_chars):
                for c, p in zip(h_chars, p_parts):
                    char_data[c]["counts"][p] += 1
                    if len(char_data[c]["examples"][p]) < 3:  # æœ€å¤šä¿ç•™3ä¸ªç¤ºä¾‹
                        char_data[c]["examples"][p].append(
                            f"{lesson.filename}: #r(\"{pair.pinyin}\", \"{pair.hanzi}\")"
                        )
    
    result = {}
    for char, data in char_data.items():
        counts = data["counts"]
        if not counts:
            continue
        main_py = max(counts.keys(), key=lambda x: counts[x])
        total = sum(counts.values())
        # æ”¶é›†æ‰€æœ‰ç¤ºä¾‹
        all_examples = []
        for py, exs in data["examples"].items():
            all_examples.extend(exs)
        
        result[char] = CharPronInfo(
            main_pinyin=main_py,
            main_count=counts[main_py],
            total_count=total,
            all_pinyins=dict(counts),
            examples=all_examples[:5]
        )
    
    return result

def analyze_ruby_pair(pinyin: str, hanzi: str, pron_db: Dict[str, CharPronInfo]) -> Optional[FixSuggestion]:
    """åˆ†æå•ä¸ª Ruby å¯¹æ˜¯å¦éœ€è¦ä¿®å¤"""
    p_parts = re.split(r'[-\s]', normalize_pinyin(pinyin))
    h_chars = split_characters(hanzi)
    
    original = f'#r("{pinyin}", "{hanzi}")'
    
    # 0. ä¿æŠ¤æœºåˆ¶ï¼šå è¯æ£€æŸ¥ (å¦‚ "leh-la" "æ‹‰æ‹‰")
    # å¦‚æœæ±‰å­—æ˜¯å è¯ï¼Œæ— è®ºæ‹¼éŸ³å½¢å¼å¦‚ä½•ï¼Œéƒ½ä¸åšæ‹¼å†™ä¿®æ­£
    # å› ä¸ºä¸Šæµ·è¯å è¯æœ‰å¤æ‚çš„è¿è¯»å˜è°ƒè§„åˆ™ (å¦‚ leh-la, khoe-kho ç­‰)
    is_hanzi_reduplication = len(h_chars) >= 2 and h_chars[0] == h_chars[1]
    
    # æƒ…å†µ1: é•¿åº¦åŒ¹é…ï¼Œæ£€æŸ¥æ‹¼å†™é”™è¯¯
    if len(p_parts) == len(h_chars):
        for i, (char, py) in enumerate(zip(h_chars, p_parts)):
            if char in pron_db:
                info = pron_db[char]
                expected = info.main_pinyin
                sim = get_similarity(expected, py)
                
                # è·³è¿‡å¤šéŸ³å­— (å¯èƒ½æ˜¯åˆç†å˜ä½“)
                if info.is_polyphonic and py in info.all_pinyins:
                    continue
                
                # ä½¿ç”¨ Rime è¯å…¸ + éŸ³ç³»ç›¸ä¼¼åº¦éªŒè¯ï¼š
                # å¦‚æœå½“å‰æ‹¼éŸ³æ˜¯è¯¥å­—çš„åˆæ³•è¯»éŸ³å˜ä½“ï¼ˆè€ƒè™‘æ•™ä¼šç½—é©¬å­—åˆ°å´è¯­å­¦å ‚çš„è½¬æ¢ï¼‰ï¼Œè·³è¿‡ä¿®æ­£
                if is_valid_pronunciation(char, py):
                    continue
                    
                if sim < 0.5 and sim > 0:
                    # å è¯ä¿æŠ¤ï¼šå¯¹äºå è¯æ±‰å­—ï¼Œä¸åšè‡ªåŠ¨æ‹¼å†™ä¿®æ­£
                    if is_hanzi_reduplication:
                        continue  # è·³è¿‡ï¼Œä¸å»ºè®®ä¿®æ”¹å è¯çš„è¯»éŸ³
                    
                    new_parts = p_parts.copy()
                    new_parts[i] = expected
                    new_pinyin = "-".join(new_parts)
                    
                    # æ ¹æ®ç½®ä¿¡åº¦ç¡®å®šå®‰å…¨ç­‰çº§
                    safety = SafetyLevel.SAFE if info.confidence > 0.95 else \
                             SafetyLevel.REVIEW if info.confidence > 0.7 else \
                             SafetyLevel.MANUAL
                    
                    return FixSuggestion(
                        file="", line_num=0,
                        strategy=FixStrategy.REPLACE_PINYIN,
                        original=original,
                        problem=f"æ‹¼å†™é”™è¯¯: '{py}' â†’ '{expected}' (å­—: {char}, ç½®ä¿¡åº¦: {info.confidence:.0%})",
                        suggestion=f'#r("{new_pinyin}", "{hanzi}")',
                        confidence=info.confidence,
                        safety=safety,
                        corpus_examples=info.examples[:3]
                    )
        return None
    
    # æƒ…å†µ2: æ±‰å­—æ¯”æ‹¼éŸ³å¤š (æ¼å­—)
    if len(h_chars) > len(p_parts):
        missing_chars = []
        inferred_pinyins = []
        min_confidence = 1.0
        examples = []
        
        for char in h_chars:
            if char in pron_db:
                info = pron_db[char]
                inferred_pinyins.append((char, info.main_pinyin))
                min_confidence = min(min_confidence, info.confidence)
                examples.extend(info.examples[:1])
            else:
                missing_chars.append(char)
                inferred_pinyins.append((char, None))
        
        if not missing_chars:
            new_rubies = " ".join([f'#r("{py}", "{c}")' for c, py in inferred_pinyins])
            safety = SafetyLevel.SAFE if min_confidence > 0.95 else \
                     SafetyLevel.REVIEW if min_confidence > 0.7 else \
                     SafetyLevel.MANUAL
            return FixSuggestion(
                file="", line_num=0,
                strategy=FixStrategy.SPLIT_RUBY,
                original=original,
                problem=f"æ±‰å­— ({len(h_chars)}å­—) > æ‹¼éŸ³ ({len(p_parts)}èŠ‚)",
                suggestion=new_rubies,
                confidence=min_confidence,
                safety=safety,
                corpus_examples=examples[:3]
            )
        else:
            return FixSuggestion(
                file="", line_num=0,
                strategy=FixStrategy.SPLIT_RUBY,
                original=original,
                problem=f"æ±‰å­— ({len(h_chars)}å­—) > æ‹¼éŸ³ ({len(p_parts)}èŠ‚), æ— æ³•æ¨æ–­ '{missing_chars[0]}'",
                suggestion="",
                confidence=0.0,
                safety=SafetyLevel.MANUAL,
                needs_input=True,
                missing_char=missing_chars[0]
            )
    
    # æƒ…å†µ3: æ‹¼éŸ³æ¯”æ±‰å­—å¤š
    if len(p_parts) > len(h_chars):
        return FixSuggestion(
            file="", line_num=0,
            strategy=FixStrategy.MERGE_RUBY,
            original=original,
            problem=f"æ‹¼éŸ³ ({len(p_parts)}èŠ‚) > æ±‰å­— ({len(h_chars)}å­—)",
            suggestion="",
            confidence=0.0,
            safety=SafetyLevel.MANUAL,
            needs_input=True
        )
    
    return None


def scan_file_for_fixes(lesson: LessonFile, pron_db: Dict[str, str]) -> List[FixSuggestion]:
    """æ‰«æå•ä¸ªæ–‡ä»¶ï¼Œè¿”å›æ‰€æœ‰ä¿®å¤å»ºè®®"""
    suggestions = []
    
    # ä½¿ç”¨æ­£åˆ™æ‰¾å‡ºæ‰€æœ‰ #r(...) å¹¶è®°å½•è¡Œå·
    lines = lesson.content.split('\n')
    pattern = r'#r\("([^"]+)",\s*"([^"]+)"\)'
    
    for line_num, line in enumerate(lines, 1):
        for match in re.finditer(pattern, line):
            pinyin, hanzi = match.group(1), match.group(2)
            fix = analyze_ruby_pair(pinyin, hanzi, pron_db)
            if fix:
                fix.file = lesson.filename
                fix.line_num = line_num
                suggestions.append(fix)
    
    return suggestions

def apply_fix(file_path: Path, suggestion: FixSuggestion, backup: bool = True) -> bool:
    """åº”ç”¨å•æ¡ä¿®å¤åˆ°æ–‡ä»¶"""
    if not suggestion.suggestion:
        return False
    
    content = file_path.read_text(encoding='utf-8')
    
    if suggestion.original not in content:
        return False
    
    if backup:
        backup_path = file_path.with_suffix(file_path.suffix + '.bak')
        if not backup_path.exists():
            shutil.copy(file_path, backup_path)
    
    new_content = content.replace(suggestion.original, suggestion.suggestion, 1)
    file_path.write_text(new_content, encoding='utf-8')
    return True

def run_fixer(
    lessons_dir: Path,
    target: Optional[str] = None,
    dry_run: bool = True,
    interactive: bool = False,
    auto: bool = False,
    backup: bool = True
):
    """ä¸»ä¿®å¤å…¥å£"""
    print("="*80)
    print("Ruby å¯¹ä¿®å¤å·¥å…·")
    print("="*80)
    
    # åŠ è½½æ•°æ®
    lessons = load_lessons(lessons_dir)
    if not lessons:
        print("æœªæ‰¾åˆ°è¯¾ç¨‹æ–‡ä»¶")
        return
    
    # è¿‡æ»¤ç›®æ ‡
    if target and target != "--all":
        lessons = [lsn for lsn in lessons if target in lsn.filename]
        if not lessons:
            print(f"æœªæ‰¾åˆ°åŒ¹é… '{target}' çš„æ–‡ä»¶")
            return
    
    # å»ºç«‹å‘éŸ³æ•°æ®åº“
    all_lessons = load_lessons(lessons_dir)  # å…¨éƒ¨ç”¨äºå»ºåº“
    pron_db = build_pronunciation_db(all_lessons)
    print(f"å·²å»ºç«‹ {len(pron_db)} å­—å‘éŸ³æ•°æ®åº“")
    
    # æ‰«æé—®é¢˜
    all_fixes = []
    for lesson in lessons:
        fixes = scan_file_for_fixes(lesson, pron_db)
        all_fixes.extend(fixes)
    
    if not all_fixes:
        print("\nâœ… æœªå‘ç°éœ€è¦ä¿®å¤çš„é—®é¢˜")
        return
    
    print(f"\nå‘ç° {len(all_fixes)} å¤„å¾…ä¿®å¤é—®é¢˜")
    
    # æŒ‰æ–‡ä»¶åˆ†ç»„æ˜¾ç¤º
    by_file = defaultdict(list)
    for fix in all_fixes:
        by_file[fix.file].append(fix)
    
    fixed_count = 0
    skipped_count = 0
    
    for filename, fixes in by_file.items():
        # æŒ‰å®‰å…¨ç­‰çº§åˆ†ç»„ç»Ÿè®¡
        safe_count = sum(1 for f in fixes if f.safety == SafetyLevel.SAFE)
        review_count = sum(1 for f in fixes if f.safety == SafetyLevel.REVIEW)
        manual_count = sum(1 for f in fixes if f.safety == SafetyLevel.MANUAL)
        
        print(f"\nğŸ“„ {filename} ({len(fixes)} å¤„: ğŸŸ¢{safe_count} ğŸŸ¡{review_count} ğŸ”´{manual_count})")
        file_path = lessons_dir / filename
        
        for i, fix in enumerate(fixes, 1):
            # å®‰å…¨ç­‰çº§æ ‡è®°
            safety_icon = "ğŸŸ¢" if fix.safety == SafetyLevel.SAFE else \
                          "ğŸŸ¡" if fix.safety == SafetyLevel.REVIEW else "ğŸ”´"
            
            print(f"\n  [{i}/{len(fixes)}] {safety_icon} ç¬¬ {fix.line_num} è¡Œ")
            print(f"  åŸæ–‡: {fix.original}")
            print(f"  é—®é¢˜: {fix.problem}")
            
            if fix.suggestion:
                print(f"  å»ºè®®: {fix.suggestion}")
                print(f"  ç½®ä¿¡åº¦: {fix.confidence:.0%} | å®‰å…¨ç­‰çº§: {fix.safety.name}")
            
            # æ˜¾ç¤ºå…¨ä¹¦ä¸Šä¸‹æ–‡
            if fix.corpus_examples:
                print("  ğŸ“– å…¨ä¹¦ç”¨ä¾‹:")
                for ex in fix.corpus_examples[:2]:
                    print(f"     {ex}")
            
            if dry_run:
                print("  [DRY-RUN] è·³è¿‡")
                continue
            
            if fix.needs_input:
                if interactive:
                    user_input = input(f"  è¾“å…¥ '{fix.missing_char}' çš„æ‹¼éŸ³ (ç•™ç©ºè·³è¿‡): ").strip()
                    if user_input:
                        print(f"  â†’ éœ€æ‰‹åŠ¨ç¼–è¾‘æ–‡ä»¶æ·»åŠ : #r(\"{user_input}\", \"{fix.missing_char}\")")
                    skipped_count += 1
                else:
                    print("  [éœ€æ‰‹åŠ¨å¤„ç†]")
                    skipped_count += 1
                continue
            
            # è‡ªåŠ¨æ¨¡å¼ï¼šåªè‡ªåŠ¨åº”ç”¨ SAFE çº§åˆ«çš„ä¿®å¤
            if auto:
                if fix.safety == SafetyLevel.SAFE:
                    if apply_fix(file_path, fix, backup):
                        print("  âœ“ å·²è‡ªåŠ¨ä¿®å¤ (SAFE)")
                        fixed_count += 1
                    else:
                        print("  âœ— ä¿®å¤å¤±è´¥")
                        skipped_count += 1
                else:
                    print(f"  [è·³è¿‡] å®‰å…¨ç­‰çº§ä¸º {fix.safety.name}ï¼Œéœ€äººå·¥å¤„ç†")
                    skipped_count += 1
                continue
            
            if interactive:
                choice = input("  åº”ç”¨ä¿®å¤? [y/n/s=è·³è¿‡æ–‡ä»¶/q=é€€å‡º] > ").strip().lower()
                if choice == 'q':
                    print("\nå·²é€€å‡º")
                    return
                if choice == 's':
                    print(f"  è·³è¿‡æ–‡ä»¶ {filename}")
                    break
                if choice != 'y':
                    skipped_count += 1
                    continue
                    
                if apply_fix(file_path, fix, backup):
                    print("  âœ“ å·²ä¿®å¤")
                    fixed_count += 1
                else:
                    print("  âœ— ä¿®å¤å¤±è´¥")
                    skipped_count += 1
    
    print("\n" + "="*80)
    print(f"å®Œæˆ! ä¿®å¤ {fixed_count} å¤„, è·³è¿‡ {skipped_count} å¤„")
    if dry_run:
        print("(å¹²è¿è¡Œæ¨¡å¼ï¼Œæœªå®é™…ä¿®æ”¹æ–‡ä»¶)")

