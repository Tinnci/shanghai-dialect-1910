"""
å¹³è¡Œè¯­æ–™æå–ä¸Žè§„åˆ™å­¦ä¹ å·¥å…·

ä»Žæœ¬ä¹¦çš„ Ruby å¯¹å’Œ Rime è¯å…¸ä¸­æå–å¹³è¡Œè¯­æ–™ï¼Œè‡ªåŠ¨å­¦ä¹ è½¬æ¢è§„åˆ™ã€‚
"""

import re
from pathlib import Path
from typing import List, Tuple, Set

try:
    from .loader import load_lessons
    from .rime_dict import get_rime_data
    from .rule_induction import RuleInductionEngine, phonetic_feature_similarity
except ImportError:
    from loader import load_lessons
    from rime_dict import get_rime_data
    from rule_induction import RuleInductionEngine, phonetic_feature_similarity


def extract_parallel_corpus(lessons_dir: Path) -> List[Tuple[str, str, str]]:
    """
    ä»Žæœ¬ä¹¦ä¸­æå–å¹³è¡Œè¯­æ–™

    è¿”å›ž: [(church_pinyin, wugniu_pinyin, hanzi), ...]
    """
    lessons = load_lessons(lessons_dir)
    char_pinyins, _, _ = get_rime_data()

    parallel_pairs = []

    for lesson in lessons:
        for pair in lesson.pairs:
            pinyin = pair.pinyin.lower().strip("',.-")
            hanzi = pair.hanzi

            # åˆ†å‰²å¤šéŸ³èŠ‚
            py_parts = re.split(r"[-\s]", pinyin)
            hz_chars = list(hanzi)

            # åªå¤„ç†é•¿åº¦åŒ¹é…çš„
            if len(py_parts) == len(hz_chars):
                for church_py, char in zip(py_parts, hz_chars):
                    if char in char_pinyins:
                        # æ‰¾åˆ°æœ€åŒ¹é…çš„ Rime è¯»éŸ³
                        wugniu_variants = char_pinyins[char]
                        best_match = find_best_match(church_py, wugniu_variants)
                        if best_match:
                            parallel_pairs.append((church_py, best_match, char))

    return parallel_pairs


def find_best_match(church_py: str, wugniu_variants: Set[str]) -> str:
    """æ‰¾åˆ°ä¸Žæ•™ä¼šç½—é©¬å­—æœ€åŒ¹é…çš„å´è¯­å­¦å ‚æ‹¼éŸ³"""
    best_sim = 0
    best_match = ""

    for variant in wugniu_variants:
        # ç®€å•çš„å­—ç¬¦ç›¸ä¼¼åº¦ + éŸ³éŸµç‰¹å¾ç›¸ä¼¼åº¦
        sim = calculate_similarity(church_py, variant)
        if sim > best_sim:
            best_sim = sim
            best_match = variant

    return best_match if best_sim > 0.5 else ""


def calculate_similarity(church_py: str, wugniu_py: str) -> float:
    """è®¡ç®—ä¸¤ä¸ªæ‹¼éŸ³çš„ç›¸ä¼¼åº¦"""
    # åˆ†ç¦»å£°æ¯éŸµæ¯
    c_init, c_final = split_syllable(church_py, is_wugniu=False)
    w_init, w_final = split_syllable(wugniu_py, is_wugniu=True)

    # ä½¿ç”¨éŸ³éŸµç‰¹å¾ç›¸ä¼¼åº¦
    return phonetic_feature_similarity(c_init, c_final, w_init, w_final)


def split_syllable(syllable: str, is_wugniu: bool = False) -> Tuple[str, str]:
    """åˆ†ç¦»å£°æ¯å’ŒéŸµæ¯"""
    syllable = syllable.lower().strip("',.-")
    if not syllable:
        return "", ""

    if is_wugniu:
        initials = [
            "tsh",
            "dz",
            "ts",
            "ng",
            "gn",
            "kh",
            "ph",
            "th",
            "gh",
            "ch",
            "sh",
            "zh",
            "k",
            "h",
            "m",
            "n",
            "l",
            "v",
            "w",
            "f",
            "p",
            "b",
            "t",
            "d",
            "s",
            "z",
            "j",
            "c",
            "q",
            "x",
            "y",
            "'",
            "lh",
        ]
    else:
        initials = [
            "tsh",
            "dz",
            "ts",
            "ng",
            "ny",
            "kh",
            "ph",
            "th",
            "gh",
            "ch",
            "sh",
            "ky",
            "hy",
            "kw",
            "gw",
            "hw",
            "k",
            "h",
            "m",
            "n",
            "l",
            "v",
            "w",
            "f",
            "p",
            "b",
            "t",
            "d",
            "s",
            "z",
            "j",
            "y",
            "'",
            "'v",
        ]

    for init in sorted(initials, key=lambda x: -len(x)):
        if syllable.startswith(init):
            return init, syllable[len(init) :]

    return "", syllable


def learn_rules_from_corpus(lessons_dir: Path):
    """ä»Žè¯­æ–™ä¸­å­¦ä¹ è§„åˆ™"""
    print("=" * 70)
    print("å¹³è¡Œè¯­æ–™è§„åˆ™å­¦ä¹  (Parallel Corpus Rule Learning)")
    print("=" * 70)

    # æå–å¹³è¡Œè¯­æ–™
    print("\nðŸ“š æ­£åœ¨æå–å¹³è¡Œè¯­æ–™...")
    pairs = extract_parallel_corpus(lessons_dir)
    print(f"   æå–äº† {len(pairs)} å¯¹å¹³è¡Œæ‹¼éŸ³")

    # å­¦ä¹ è§„åˆ™
    engine = RuleInductionEngine()
    for church, wugniu, hanzi in pairs:
        engine.add_parallel_pair(church, wugniu, hanzi)

    # è¾“å‡ºè§„åˆ™
    engine.print_rules_report()

    # ç»Ÿè®¡
    initial_rules, final_rules = engine.induce_rules()

    print("\n" + "=" * 70)
    print("é«˜ç½®ä¿¡åº¦è§„åˆ™ (Top Confident Rules)")
    print("=" * 70)

    print("\nå£°æ¯è§„åˆ™ (å‡ºçŽ° >= 10 æ¬¡):")
    for rule in initial_rules:
        if rule.count >= 10:
            print(f"  âœ“ '{rule.source}' â†’ '{rule.target}' (å‡ºçŽ° {rule.count} æ¬¡)")

    print("\néŸµæ¯è§„åˆ™ (å‡ºçŽ° >= 10 æ¬¡):")
    for rule in final_rules:
        if rule.count >= 10:
            print(f"  âœ“ '{rule.source}' â†’ '{rule.target}' (å‡ºçŽ° {rule.count} æ¬¡)")

    return initial_rules, final_rules


if __name__ == "__main__":
    lessons_dir = Path(__file__).parent.parent / "typst_source/contents/lessons"
    learn_rules_from_corpus(lessons_dir)
